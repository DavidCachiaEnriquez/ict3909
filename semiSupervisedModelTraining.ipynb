{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKev4lhb-9T"
      },
      "source": [
        "## Instal Toolkit, Import Libraries, Access Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGbSejQ_FUC",
        "outputId": "add2c993-fb77-4819-f19a-b092c31ef7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting LAMDA-SSL\n",
            "  Downloading LAMDA_SSL-1.0.2-py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.8/240.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (1.2.2)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (0.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (0.16.0+cu118)\n",
            "Collecting torch-geometric (from LAMDA-SSL)\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (1.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from LAMDA-SSL) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->LAMDA-SSL) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->LAMDA-SSL) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->LAMDA-SSL) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->LAMDA-SSL) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric->LAMDA-SSL) (4.66.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric->LAMDA-SSL) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric->LAMDA-SSL) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric->LAMDA-SSL) (5.9.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext->LAMDA-SSL) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext->LAMDA-SSL) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext->LAMDA-SSL) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext->LAMDA-SSL) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->LAMDA-SSL) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric->LAMDA-SSL) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->LAMDA-SSL) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->LAMDA-SSL) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->LAMDA-SSL) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext->LAMDA-SSL) (1.3.0)\n",
            "Installing collected packages: torch-geometric, LAMDA-SSL\n",
            "Successfully installed LAMDA-SSL-1.0.2 torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install LAMDA-SSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ivt8_-T4LCSD"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# General Libraries\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "\n",
        "# For Training\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from LAMDA_SSL.Split.ViewSplit import ViewSplit\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Measurements\n",
        "from LAMDA_SSL.Evaluation.Classifier.Accuracy import Accuracy\n",
        "from LAMDA_SSL.Evaluation.Classifier.Precision import Precision\n",
        "from LAMDA_SSL.Evaluation.Classifier.Recall import Recall\n",
        "from LAMDA_SSL.Evaluation.Classifier.F1 import F1\n",
        "from LAMDA_SSL.Evaluation.Classifier.AUC import AUC\n",
        "from LAMDA_SSL.Evaluation.Classifier.Confusion_Matrix import Confusion_Matrix\n",
        "\n",
        "# Supervised Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Semi-Supervised Models\n",
        "from LAMDA_SSL.Algorithm.Classification.Co_Training import Co_Training\n",
        "from LAMDA_SSL.Algorithm.Classification.Tri_Training import Tri_Training\n",
        "from LAMDA_SSL.Algorithm.Classification.SSGMM import SSGMM\n",
        "from LAMDA_SSL.Algorithm.Classification.Assemble import Assemble\n",
        "from LAMDA_SSL.Algorithm.Classification.SemiBoost import SemiBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk6nfFj4DuE9",
        "outputId": "39ed9f79-71a1-4c3a-f01c-15917c56ccf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Final Year Project\n"
          ]
        }
      ],
      "source": [
        "if(os.getcwd() != \"/content/drive/MyDrive/Final Year Project\"):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  %cd /content/drive/MyDrive/Final Year Project/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YgF1b4-10nn"
      },
      "source": [
        "## Dataset Initialisation and Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HAwqRuMkJvxX"
      },
      "outputs": [],
      "source": [
        "# CSV Dataset\n",
        "recolaDataset = pd.read_csv(\"Datasets/RecolaLabelledFull.csv\")\n",
        "\n",
        "# Features\n",
        "audioFeatures = recolaDataset.filter(regex=f'^{\"ComPar\"}|{\"audio_speech\"}', axis=1)\n",
        "visualFeatures = recolaDataset.filter(regex=f'^{\"VIDEO\"}|{\"Face_detection\"}', axis=1)\n",
        "physiologyFeatures = recolaDataset.filter(regex=f'^{\"ECG\"}|{\"EDA\"}', axis=1)\n",
        "allFeatures = recolaDataset.filter(regex=f'^{\"ComPar\"}|{\"audio_speech\"}|{\"VIDEO\"}|{\"Face_detection\"}|{\"ECG\"}|{\"EDA\"}', axis=1)\n",
        "\n",
        "# Labels\n",
        "targetArousal = recolaDataset[\"classLabelArousal\"]\n",
        "targetValence = recolaDataset[\"classLabelValence\"]\n",
        "\n",
        "# Number of Folds\n",
        "folds = 9\n",
        "\n",
        "# Groups\n",
        "groups = list(recolaDataset[\"Participant\"])\n",
        "\n",
        "# Folder to save results\n",
        "saveFolder = \"SemiSupervisedResults(Test)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B5pb_SZsUqv2"
      },
      "outputs": [],
      "source": [
        "# Different kinds of input\n",
        "featureList = [\"Audio\", \"Visual\", \"Phys\", \"All\"]\n",
        "targetList = [\"Arousal\", \"Valence\"]\n",
        "baseEstList = [\"BLR\", \"RF\", \"NN\"]\n",
        "labelledCount = [\"4\", \"8\", \"12\"]\n",
        "\n",
        "# Dictionary with input meanings\n",
        "valueDict = {\n",
        "    \"Audio\": audioFeatures,\n",
        "    \"Visual\": visualFeatures,\n",
        "    \"Phys\": physiologyFeatures,\n",
        "    \"All\": allFeatures,\n",
        "    \"Arousal\": targetArousal,\n",
        "    \"Valence\": targetValence,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUUg3Iv6xZZ_"
      },
      "source": [
        "## Co-Training (with Group k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d7d45y5ZF_Ky"
      },
      "outputs": [],
      "source": [
        "def coTraining(estimatorType, feature, label, folds, groups, labelledCount, fileName):\n",
        "  # Lists to store results\n",
        "  foldNumber = []\n",
        "  trainAccuracy = []\n",
        "  trainPrecision = []\n",
        "  testAccuracy = []\n",
        "  testPrecision = []\n",
        "  confusionMatrixList = []\n",
        "\n",
        "  group_kfold = GroupKFold(n_splits = folds)\n",
        "  for train_index, test_index in group_kfold.split(feature, label, groups):\n",
        "    # Getting Train and Test Sets\n",
        "    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n",
        "    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n",
        "\n",
        "    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n",
        "    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n",
        "    random.shuffle(labeled_mask)\n",
        "\n",
        "    # Train Set Labelled Data\n",
        "    labeledFeatures = trainFeatures[labeled_mask]\n",
        "    labeledLabels = trainLabels[labeled_mask]\n",
        "\n",
        "    # Train Set Unlabelled Data\n",
        "    unlabeledFeatures = trainFeatures[~labeled_mask]\n",
        "    unlabeledLabels = trainLabels[~labeled_mask]\n",
        "\n",
        "    # For Evaluation\n",
        "    evaluation={\n",
        "      'Accuracy':Accuracy(),\n",
        "      'Precision':Precision(average='macro'),\n",
        "      'ConfusionMatrix':Confusion_Matrix()\n",
        "    }\n",
        "\n",
        "    # Choosing base estimators\n",
        "    if estimatorType == \"BLR\":\n",
        "      estimator1 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "      estimator2 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "    elif estimatorType == \"RF\":\n",
        "      estimator1 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "      estimator2 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "    elif estimatorType == \"NN\":\n",
        "      estimator1 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "      estimator2 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "    else: raise Exception(\"Invalid\")\n",
        "\n",
        "    # Creating and fitting Model\n",
        "    model = Co_Training(base_estimator = estimator1, base_estimator_2 = estimator2, evaluation=evaluation)\n",
        "    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n",
        "\n",
        "    # Getting Performance Results\n",
        "    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n",
        "    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n",
        "\n",
        "    # Append results\n",
        "    foldNumber.append(len(foldNumber)+1)\n",
        "    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n",
        "    trainPrecision.append(performanceTrain[\"Precision\"])\n",
        "    testAccuracy.append(performanceTest[\"Accuracy\"])\n",
        "    testPrecision.append(performanceTest[\"Precision\"])\n",
        "    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n",
        "\n",
        "  # Save per fold results\n",
        "  csvFile = pd.DataFrame({\"foldNumber\": foldNumber,\n",
        "                          \"trainAccuracy\": trainAccuracy,\n",
        "                          \"trainPrecision\": trainPrecision,\n",
        "                          \"testAccuracy\": testAccuracy,\n",
        "                          \"testPrecision\": testPrecision})\n",
        "  csvFile.to_csv(\"SemiSupervisedResults/CoTraining/PerFolds/\" + fileName + \".csv\", index=False)\n",
        "\n",
        "  # Save average model results\n",
        "  txtFileName = \"SemiSupervisedResults/CoTraining/Average/\" + fileName + \".txt\"\n",
        "  MTrainAccuracy = \"Mean Train Accuracy: \" + str(np.mean(trainAccuracy))\n",
        "  MTrainPrecision = \"\\nMean Train Precision: \" + str(np.mean(trainPrecision))\n",
        "  MTestAccuracy = \"\\nMean Test Accuracy: \" + str(np.mean(testAccuracy))\n",
        "  MTestPrecision = \"\\nMean Test Precision: \" + str(np.mean(testPrecision))\n",
        "  MConfusionMatrix = \"\\nMean Confusion Matrix:\\n\" + str(np.mean(confusionMatrixList, axis=0))\n",
        "\n",
        "  with open(txtFileName, \"w\") as file:\n",
        "    file.write(MTrainAccuracy)\n",
        "    file.write(MTrainPrecision)\n",
        "    file.write(MTestAccuracy)\n",
        "    file.write(MTestPrecision)\n",
        "    file.write(MConfusionMatrix)\n",
        "    file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9omdgNqcaKb",
        "outputId": "771f0796-1ee8-4735-cbb8-3f6c1eece298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Tests: 3/72 - ['AudioArousalBLR4', 'AudioArousalBLR8', 'AudioArousalBLR12']\n",
            "AudioArousalRF4\n"
          ]
        }
      ],
      "source": [
        "# with open(\"SemiSupervisedResults/CoTraining/NoCopyChecker.txt\", \"w\") as file:\n",
        "#   file.close\n",
        "\n",
        "completed  = []\n",
        "with open(\"SemiSupervisedResults/CoTraining/NoCopyChecker.txt\", \"r+\") as file:\n",
        "  completed  = file.read()\n",
        "  file.close()\n",
        "completed = completed.split()\n",
        "print(\"Completed Tests: \" + str(len(completed)) + \"/72 - \" + str(completed))\n",
        "\n",
        "for i in featureList:\n",
        "  for j in targetList:\n",
        "    for k in baseEstList:\n",
        "      for l in labelledCount:\n",
        "        fileName = i + j + k + l\n",
        "        if fileName not in completed:\n",
        "          start = time.time()\n",
        "\n",
        "          print(fileName)\n",
        "          coTraining(k, valueDict[i], valueDict[j], folds, groups, int(l), fileName)\n",
        "\n",
        "          end = time.time()\n",
        "          print(\"Done: \" + str(end-start) + \"\\n\")\n",
        "\n",
        "          with open(\"SemiSupervisedResults/CoTraining/NoCopyChecker.txt\", \"a\") as file:\n",
        "            file.write(fileName + \" \")\n",
        "            file.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hmchjlvx9Ah"
      },
      "source": [
        "## Tri-Training (with Group k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxkK5W5qU--C"
      },
      "outputs": [],
      "source": [
        "def triTraining(estimatorType, feature, label, folds, groups, labelledCount, fileName):\n",
        "  # Lists to store results\n",
        "  foldNumber = []\n",
        "  trainAccuracy = []\n",
        "  trainPrecision = []\n",
        "  testAccuracy = []\n",
        "  testPrecision = []\n",
        "  confusionMatrixList = []\n",
        "\n",
        "  group_kfold = GroupKFold(n_splits=folds)\n",
        "  for train_index, test_index in group_kfold.split(feature, label, groups):\n",
        "    # Getting Train and Test Sets\n",
        "    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n",
        "    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n",
        "\n",
        "    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n",
        "    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n",
        "    random.shuffle(labeled_mask)\n",
        "\n",
        "    # Train Set Labelled Data\n",
        "    labeledFeatures = trainFeatures[labeled_mask]\n",
        "    labeledLabels = trainLabels[labeled_mask]\n",
        "\n",
        "    # Train Set Unlabelled Data\n",
        "    unlabeledFeatures = trainFeatures[~labeled_mask]\n",
        "    unlabeledLabels = trainLabels[~labeled_mask]\n",
        "\n",
        "    # For Evaluation\n",
        "    evaluation={\n",
        "      'Accuracy':Accuracy(),\n",
        "      'Precision':Precision(average='macro'),\n",
        "      'ConfusionMatrix':Confusion_Matrix()\n",
        "    }\n",
        "\n",
        "    # Choosing base estimators\n",
        "    if estimatorType == \"BLR\":\n",
        "      estimator1 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "      estimator2 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "      estimator3 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "    elif estimatorType == \"RF\":\n",
        "      estimator1 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "      estimator2 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "      estimator3 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "    elif estimatorType == \"NN\":\n",
        "      estimator1 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "      estimator2 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "      estimator2 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "    else: raise Exception(\"Invalid\")\n",
        "\n",
        "    # Creating and fitting model\n",
        "    model = Tri_Training(base_estimator = estimator1, base_estimator_2 = estimator2, base_estimator_3 = estimator3, evaluation = evaluation)\n",
        "    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n",
        "\n",
        "    # Getting Performance Results\n",
        "    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n",
        "    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n",
        "\n",
        "    # Append results\n",
        "    foldNumber.append(len(foldNumber)+1)\n",
        "    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n",
        "    trainPrecision.append(performanceTrain[\"Precision\"])\n",
        "    testAccuracy.append(performanceTest[\"Accuracy\"])\n",
        "    testPrecision.append(performanceTest[\"Precision\"])\n",
        "    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n",
        "\n",
        "  # Save per fold results\n",
        "  csvFile = pd.DataFrame({\"foldNumber\": foldNumber,\n",
        "                          \"trainAccuracy\": trainAccuracy,\n",
        "                          \"trainPrecision\": trainPrecision,\n",
        "                          \"testAccuracy\": testAccuracy,\n",
        "                          \"testPrecision\": testPrecision})\n",
        "  csvFile.to_csv(\"SemiSupervisedResults/TriTraining/PerFolds/\" + fileName + \".csv\", index=False)\n",
        "\n",
        "  # Save average model results\n",
        "  txtFileName = \"SemiSupervisedResults/TriTraining/Average/\" + fileName + \".txt\"\n",
        "  MTrainAccuracy = \"Mean Train Accuracy: \" + str(np.mean(trainAccuracy))\n",
        "  MTrainPrecision = \"\\nMean Train Precision: \" + str(np.mean(trainPrecision))\n",
        "  MTestAccuracy = \"\\nMean Test Accuracy: \" + str(np.mean(testAccuracy))\n",
        "  MTestPrecision = \"\\nMean Test Precision: \" + str(np.mean(testPrecision))\n",
        "  MConfusionMatrix = \"\\nMean Confusion Matrix:\\n\" + str(np.mean(confusionMatrixList, axis=0))\n",
        "\n",
        "  with open(txtFileName, \"w\") as file:\n",
        "    file.write(MTrainAccuracy)\n",
        "    file.write(MTrainPrecision)\n",
        "    file.write(MTestAccuracy)\n",
        "    file.write(MTestPrecision)\n",
        "    file.write(MConfusionMatrix)\n",
        "    file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Va5m0pANfdCb",
        "outputId": "2d4b7248-5e0e-4a7a-d948-14950024e95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed Tests: 0/72 - []\n",
            "AudioArousalBLR4\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-813423298e20>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           \u001b[0mtriTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalueDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalueDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e42aaf798aad>\u001b[0m in \u001b[0;36mtriTraining\u001b[0;34m(estimatorType, feature, label, folds, groups, labelledCount, fileName)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Creating and fitting model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTri_Training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeledFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabeledLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munlabeledFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Getting Performance Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/LAMDA_SSL/Algorithm/Classification/Tri_Training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, unlabeled_X)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mlb_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mulb_y_j\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mulb_y_j\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mulb_y_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ml_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                         \u001b[0ml_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ml_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0me_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# with open(\"SemiSupervisedResults/TriTraining/NoCopyChecker.txt\", \"w\") as file:\n",
        "#   file.close\n",
        "\n",
        "completed  = []\n",
        "with open(\"SemiSupervisedResults/TriTraining/NoCopyChecker.txt\", \"r+\") as file:\n",
        "  completed  = file.read()\n",
        "  file.close()\n",
        "completed = completed.split()\n",
        "print(\"Completed Tests: \" + str(len(completed)) + \"/72 - \" + str(completed))\n",
        "\n",
        "for i in featureList:\n",
        "  for j in targetList:\n",
        "    for k in baseEstList:\n",
        "      for l in labelledCount:\n",
        "        fileName = i + j + k + l\n",
        "        if fileName not in completed:\n",
        "          start = time.time()\n",
        "\n",
        "          print(fileName)\n",
        "          triTraining(k, valueDict[i], valueDict[j], folds, groups, int(l), fileName)\n",
        "\n",
        "          end = time.time()\n",
        "          print(\"Done: \" + str(end-start) + \"\\n\")\n",
        "\n",
        "          with open(\"SemiSupervisedResults/TriTraining/NoCopyChecker.txt\", \"a\") as file:\n",
        "            file.write(fileName + \" \")\n",
        "            file.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arZ66yECKqa9"
      },
      "source": [
        "## SSGMM (with Group k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfhhbQgTPPo"
      },
      "outputs": [],
      "source": [
        "def SSGMMModel(feature, label, folds, groups, labelledCount, fileName):\n",
        "  # Lists to store results\n",
        "  foldNumber = []\n",
        "  trainAccuracy = []\n",
        "  trainPrecision = []\n",
        "  testAccuracy = []\n",
        "  testPrecision = []\n",
        "  confusionMatrixList = []\n",
        "\n",
        "  group_kfold = GroupKFold(n_splits = folds)\n",
        "  for train_index, test_index in group_kfold.split(feature, label, groups):\n",
        "    start = time.time()\n",
        "\n",
        "    # Getting Train and Test Sets\n",
        "    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n",
        "    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n",
        "\n",
        "    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n",
        "    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n",
        "    random.shuffle(labeled_mask)\n",
        "\n",
        "    # Train Set Labelled Data\n",
        "    labeledFeatures = trainFeatures[labeled_mask]\n",
        "    labeledLabels = trainLabels[labeled_mask]\n",
        "\n",
        "    # Train Set Unlabelled Data\n",
        "    unlabeledFeatures = trainFeatures[~labeled_mask]\n",
        "    unlabeledLabels = trainLabels[~labeled_mask]\n",
        "\n",
        "    # For Evaluation\n",
        "    evaluation={\n",
        "      'Accuracy':Accuracy(),\n",
        "      'Precision':Precision(average='macro'),\n",
        "      'ConfusionMatrix':Confusion_Matrix()\n",
        "    }\n",
        "\n",
        "    # Creating and fitting model\n",
        "    model = SSGMM(tolerance=0.000001, max_iterations = 5, evaluation = evaluation)\n",
        "    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n",
        "\n",
        "    # Getting Performance Results\n",
        "    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n",
        "    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n",
        "\n",
        "    # Append results\n",
        "    foldNumber.append(len(foldNumber)+1)\n",
        "    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n",
        "    trainPrecision.append(performanceTrain[\"Precision\"])\n",
        "    testAccuracy.append(performanceTest[\"Accuracy\"])\n",
        "    testPrecision.append(performanceTest[\"Precision\"])\n",
        "    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n",
        "\n",
        "  # Save per fold results\n",
        "  csvFile = pd.DataFrame({\"foldNumber\": foldNumber,\n",
        "                          \"trainAccuracy\": trainAccuracy,\n",
        "                          \"trainPrecision\": trainPrecision,\n",
        "                          \"testAccuracy\": testAccuracy,\n",
        "                          \"testPrecision\": testPrecision})\n",
        "  csvFile.to_csv(\"SemiSupervisedResults/SSGMM/PerFolds/\" + fileName + \".csv\", index=False)\n",
        "\n",
        "  # Save average model results\n",
        "  txtFileName = \"SemiSupervisedResults/SSGMM/Average/\" + fileName + \".txt\"\n",
        "  MTrainAccuracy = \"Mean Train Accuracy: \" + str(np.mean(trainAccuracy))\n",
        "  MTrainPrecision = \"\\nMean Train Precision: \" + str(np.mean(trainPrecision))\n",
        "  MTestAccuracy = \"\\nMean Test Accuracy: \" + str(np.mean(testAccuracy))\n",
        "  MTestPrecision = \"\\nMean Test Precision: \" + str(np.mean(testPrecision))\n",
        "  MConfusionMatrix = \"\\nMean Confusion Matrix:\\n\" + str(np.mean(confusionMatrixList, axis=0))\n",
        "\n",
        "  with open(txtFileName, \"w\") as file:\n",
        "    file.write(MTrainAccuracy)\n",
        "    file.write(MTrainPrecision)\n",
        "    file.write(MTestAccuracy)\n",
        "    file.write(MTestPrecision)\n",
        "    file.write(MConfusionMatrix)\n",
        "    file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h13eoOxklz0j"
      },
      "outputs": [],
      "source": [
        "SSGMMModel(audioFeatures, targetArousal, folds, groups, 4, saveFolder)\n",
        "\n",
        "testString = \"\"\n",
        "with open(\"SemiSupervisedResults/SSGMM/NoCopyChecker.txt\", \"w+\") as file:\n",
        "  testString = file.read()\n",
        "completed = testString.split()\n",
        "\n",
        "for i in featureList:\n",
        "  for j in targetList:\n",
        "    for l in labelledCount:\n",
        "      fileName = i + j + l\n",
        "      if fileName not in completed:\n",
        "        start = time.time()\n",
        "        print(fileName)\n",
        "        SSGMMModel(valueDict[i], valueDict[j], folds, groups, int(l), fileName)\n",
        "        end = time.time()\n",
        "        print(\"Done: \" + str(end-start) + \"\\n\")\n",
        "\n",
        "        with open(\"SemiSupervisedResults/SSGMM/NoCopyChecker.txt\", \"a\") as file:\n",
        "          file.write(fileName + \" \")\n",
        "          file.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EXgWsWQKyRy"
      },
      "source": [
        "## Assemble (with Group k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uz8afvQKXMP"
      },
      "outputs": [],
      "source": [
        "def assemble(estimatorType, feature, label, folds, groups, labelledCount, fileName):\n",
        "  # Lists to store results\n",
        "  foldNumber = []\n",
        "  trainAccuracy = []\n",
        "  trainPrecision = []\n",
        "  testAccuracy = []\n",
        "  testPrecision = []\n",
        "  confusionMatrixList = []\n",
        "\n",
        "  group_kfold = GroupKFold(n_splits=folds)\n",
        "  for train_index, test_index in group_kfold.split(feature, label, groups):\n",
        "    # Getting Train and Test Sets\n",
        "    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n",
        "    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n",
        "\n",
        "    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n",
        "    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n",
        "    random.shuffle(labeled_mask)\n",
        "\n",
        "    # Train Set Labelled Data\n",
        "    labeledFeatures = trainFeatures[labeled_mask]\n",
        "    labeledLabels = trainLabels[labeled_mask]\n",
        "\n",
        "    # Train Set Unlabelled Data\n",
        "    unlabeledFeatures = trainFeatures[~labeled_mask]\n",
        "    unlabeledLabels = trainLabels[~labeled_mask]\n",
        "\n",
        "    # For Evaluation\n",
        "    evaluation={\n",
        "      'Accuracy':Accuracy(),\n",
        "      'Precision':Precision(average='macro'),\n",
        "      'ConfusionMatrix':Confusion_Matrix()\n",
        "    }\n",
        "\n",
        "    # Choosing base estimators\n",
        "    if estimatorType == \"BLR\":\n",
        "      estimator = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "    elif estimatorType == \"RF\":\n",
        "      estimator = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "    elif estimatorType == \"NN\":\n",
        "      estimator = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "    else: raise Exception(\"Invalid\")\n",
        "\n",
        "    # Creating Model\n",
        "    model = Assemble(base_estimator = estimator, evaluation = evaluation)\n",
        "\n",
        "    # Fitting Model\n",
        "    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n",
        "\n",
        "    # Getting Performance Results\n",
        "    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n",
        "    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n",
        "\n",
        "    # Append results\n",
        "    foldNumber.append(len(foldNumber)+1)\n",
        "    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n",
        "    trainPrecision.append(performanceTrain[\"Precision\"])\n",
        "    testAccuracy.append(performanceTest[\"Accuracy\"])\n",
        "    testPrecision.append(performanceTest[\"Precision\"])\n",
        "    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n",
        "\n",
        "  # Save per fold results\n",
        "  csvFile = pd.DataFrame({\"foldNumber\": foldNumber,\n",
        "                          \"trainAccuracy\": trainAccuracy,\n",
        "                          \"trainPrecision\": trainPrecision,\n",
        "                          \"testAccuracy\": testAccuracy,\n",
        "                          \"testPrecision\": testPrecision})\n",
        "  csvFile.to_csv(\"SemiSupervisedResults/TriTraining/PerFolds/\" + fileName + \".csv\", index=False)\n",
        "\n",
        "  # Save average model results\n",
        "  txtFileName = \"SemiSupervisedResults/TriTraining/Average/\" + fileName + \".txt\"\n",
        "  MTrainAccuracy = \"Mean Train Accuracy: \" + str(np.mean(trainAccuracy))\n",
        "  MTrainPrecision = \"\\nMean Train Precision: \" + str(np.mean(trainPrecision))\n",
        "  MTestAccuracy = \"\\nMean Test Accuracy: \" + str(np.mean(testAccuracy))\n",
        "  MTestPrecision = \"\\nMean Test Precision: \" + str(np.mean(testPrecision))\n",
        "  MConfusionMatrix = \"\\nMean Confusion Matrix:\\n\" + str(np.mean(confusionMatrixList, axis=0))\n",
        "\n",
        "  with open(txtFileName, \"w\") as file:\n",
        "    file.write(MTrainAccuracy)\n",
        "    file.write(MTrainPrecision)\n",
        "    file.write(MTestAccuracy)\n",
        "    file.write(MTestPrecision)\n",
        "    file.write(MConfusionMatrix)\n",
        "    file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j3QbGcwmHWA"
      },
      "outputs": [],
      "source": [
        "testString = \"\"\n",
        "with open(\"SemiSupervisedResults/CoTraining/NoCopyChecker.txt\", \"w+\") as file:\n",
        "  testString = file.read()\n",
        "completed = testString.split()\n",
        "\n",
        "for i in featureList:\n",
        "  for j in targetList:\n",
        "    for k in baseEstList:\n",
        "      for l in labelledCount:\n",
        "        fileName = i + j + k + l\n",
        "        if fileName not in completed:\n",
        "          start = time.time()\n",
        "          print(fileName)\n",
        "          assemble(k, valueDict[i], valueDict[j], folds, groups, int(l), fileName)\n",
        "          end = time.time()\n",
        "          print(\"Done: \" + str(end-start) + \"\\n\")\n",
        "\n",
        "          with open(\"SemiSupervisedResults/Assemble/NoCopyChecker.txt\", \"a\") as file:\n",
        "            file.write(fileName + \" \")\n",
        "            file.close"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr9Kr0ZLyMQG"
      },
      "source": [
        "## SemiBoost (with Group k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0Kn5nURrIKb"
      },
      "outputs": [],
      "source": [
        "def semiBoost(estimatorType, feature, label, folds, groups, labelledCount, fileName):\n",
        "  # Lists to store results\n",
        "  foldNumber = []\n",
        "  trainAccuracy = []\n",
        "  trainPrecision = []\n",
        "  testAccuracy = []\n",
        "  testPrecision = []\n",
        "  confusionMatrixList = []\n",
        "\n",
        "  group_kfold = GroupKFold(n_splits=folds)\n",
        "  for train_index, test_index in group_kfold.split(feature, label, groups):\n",
        "    # Getting Train and Test Sets\n",
        "    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n",
        "    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n",
        "\n",
        "    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n",
        "    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n",
        "    random.shuffle(labeled_mask)\n",
        "\n",
        "    # Train Set Labelled Data\n",
        "    labeledFeatures = trainFeatures[labeled_mask]\n",
        "    labeledLabels = trainLabels[labeled_mask]\n",
        "\n",
        "    # Train Set Unlabelled Data\n",
        "    unlabeledFeatures = trainFeatures[~labeled_mask]\n",
        "    unlabeledLabels = trainLabels[~labeled_mask]\n",
        "\n",
        "    # For Evaluation\n",
        "    evaluation={\n",
        "      'Accuracy':Accuracy(),\n",
        "      'Precision':Precision(average='macro'),\n",
        "      'ConfusionMatrix':Confusion_Matrix()\n",
        "    }\n",
        "\n",
        "    # Choosing base estimators\n",
        "    if estimatorType == \"BLR\":\n",
        "      estimator = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n",
        "    elif estimatorType == \"RF\":\n",
        "      estimator = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "    elif estimatorType == \"NN\":\n",
        "      estimator = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n",
        "    else: raise Exception(\"Invalid\")\n",
        "\n",
        "    # Creating and fitting model\n",
        "    model=SemiBoost(base_estimator=estimator, evaluation=evaluation)\n",
        "    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n",
        "\n",
        "    # Getting Performance Results\n",
        "    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n",
        "    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n",
        "\n",
        "    # Append results\n",
        "    foldNumber.append(len(foldNumber)+1)\n",
        "    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n",
        "    trainPrecision.append(performanceTrain[\"Precision\"])\n",
        "    testAccuracy.append(performanceTest[\"Accuracy\"])\n",
        "    testPrecision.append(performanceTest[\"Precision\"])\n",
        "    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n",
        "\n",
        "  # Save per fold results\n",
        "  csvFile = pd.DataFrame({\"foldNumber\": foldNumber,\n",
        "                          \"trainAccuracy\": trainAccuracy,\n",
        "                          \"trainPrecision\": trainPrecision,\n",
        "                          \"testAccuracy\": testAccuracy,\n",
        "                          \"testPrecision\": testPrecision})\n",
        "  csvFile.to_csv(\"SemiSupervisedResults/SemiBoost/PerFolds/\" + fileName + \".csv\", index=False)\n",
        "\n",
        "  # Save average model results\n",
        "  txtFileName = \"SemiSupervisedResults/SemiBoost/Average/\" + fileName + \".txt\"\n",
        "  MTrainAccuracy = \"Mean Train Accuracy: \" + str(np.mean(trainAccuracy))\n",
        "  MTrainPrecision = \"\\nMean Train Precision: \" + str(np.mean(trainPrecision))\n",
        "  MTestAccuracy = \"\\nMean Test Accuracy: \" + str(np.mean(testAccuracy))\n",
        "  MTestPrecision = \"\\nMean Test Precision: \" + str(np.mean(testPrecision))\n",
        "  MConfusionMatrix = \"\\nMean Confusion Matrix:\\n\" + str(np.mean(confusionMatrixList, axis=0))\n",
        "\n",
        "  with open(txtFileName, \"w\") as file:\n",
        "    file.write(MTrainAccuracy)\n",
        "    file.write(MTrainPrecision)\n",
        "    file.write(MTestAccuracy)\n",
        "    file.write(MTestPrecision)\n",
        "    file.write(MConfusionMatrix)\n",
        "    file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-DBsYsemCPL"
      },
      "outputs": [],
      "source": [
        "testString = \"\"\n",
        "with open(\"SemiSupervisedResults/SemiBoost/NoCopyChecker.txt\", \"w+\") as file:\n",
        "  testString = file.read()\n",
        "completed = testString.split()\n",
        "\n",
        "for i in featureList:\n",
        "  for j in targetList:\n",
        "    for k in baseEstList:\n",
        "      for l in labelledCount:\n",
        "        fileName = i + j + k + l\n",
        "        if fileName not in completed:\n",
        "          start = time.time()\n",
        "          print(fileName)\n",
        "          semiBoost(k, valueDict[i], valueDict[j], folds, groups, int(l), fileName)\n",
        "          end = time.time()\n",
        "          print(\"Done: \" + str(end-start) + \"\\n\")\n",
        "\n",
        "          with open(\"SemiSupervisedResults/SemiBoost/NoCopyChecker.txt\", \"a\") as file:\n",
        "            file.write(fileName + \" \")\n",
        "            file.close"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HDKev4lhb-9T",
        "_YgF1b4-10nn",
        "5Hmchjlvx9Ah",
        "arZ66yECKqa9",
        "5EXgWsWQKyRy",
        "Xr9Kr0ZLyMQG"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGSCkaQGFGYVBq4jGld645"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}